## Language Model

### Analysis

* [【论文串讲】从GPT和BERT到XLNet](https://zhuanlan.zhihu.com/p/208653273)



### Bert

* [【开源】最强NLP模型BERT的Pytorch实现，提供转换脚本](https://zhuanlan.zhihu.com/p/49469143)
* [NLP历史突破！谷歌BERT模型狂破11项纪录，全面超越人类！](https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652028621&idx=1&sn=5366f2a95bc19862af2c4bbd468ccc19&chksm=f121ca3cc656432aeb0a8ed60bd60a18ffaa977965bc4b8166f70dc119c34bc02094c3905256&scene=21#wechat_redirect)
* [【专家解读】狂破11项记录，谷歌年度最强NLP论文到底强在哪里？](https://zhuanlan.zhihu.com/p/46880276)
* [谷歌最强NLP模型BERT官方代码来了！GitHub一天3000星](https://zhuanlan.zhihu.com/p/48731842)
* [解读谷歌最强NLP模型BERT：模型、数据和训练](https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652029114&idx=3&sn=2afe6bdc130bc1dffa5f801a9a4eb625&chksm=f121b44bc6563d5d07691a5f15ceb3e6a1adc77b0c1315eee682905406886738d14fcdcb2883&scene=21#wechat_redirect)
* [谷歌最强NLP模型BERT官方代码来了！GitHub一天3000星](https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652030059&idx=6&sn=3921ed66bd027b4aaf764a5321fd35dc&chksm=f121b09ac656398c05809806ec3b0b8144d96912ced2e4202aa6fa9d6e438cdfc30df12f26e4&scene=21#wechat_redirect)
* [谷歌最强NLP模型BERT官方中文版来了！多语言模型支持100种语言](https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652030365&idx=6&sn=52380a13254c8926ffa232a383985f84&chksm=f121b16cc656387aa3a338724ff8c56001c212d6e38f7c7adc3973771b714be23199b5f5cdc1&scene=21#wechat_redirect)
* [最强NLP模型BERT喜迎🤗PyTorch版：谷歌官方推荐，也会支持中文](最强NLP模型BERT喜迎🤗PyTorch版：谷歌官方推荐，也会支持中文)
* [韩国小哥哥用Pytorch实现谷歌最强NLP预训练模型BERT｜代码](https://zhuanlan.zhihu.com/p/47228174)
* [nlp中的预训练语言模型总结(单向模型、BERT系列模型、XLNet)](https://zhuanlan.zhihu.com/p/76912493)
* [全面超越人类！Google称霸SQuAD，BERT横扫11大NLP测试](https://zhuanlan.zhihu.com/p/46648916)
* [韩国小哥哥用Pytorch实现谷歌最强NLP预训练模型BERT｜代码](https://zhuanlan.zhihu.com/p/47228174)
* [谷歌最强NLP模型BERT如约开源，12小时GitHub标星破1500，即将支持中文](https://zhuanlan.zhihu.com/p/48203943)



### Switch Transformer

* [1.6万亿参数，秒杀GPT-3！谷歌超级语言模型Switch Transformer，比T5快4倍](https://zhuanlan.zhihu.com/p/343969257)



### AMBERT

* [AMBERT模型：来自字节跳动的预训练模型](https://zhuanlan.zhihu.com/p/239849595)



### GPT2

* [15 亿参数！史上最强通用 NLP 模型诞生：狂揽 7 大数据集最佳纪录](https://zhuanlan.zhihu.com/p/56782610)
* [15 亿参数的OpenAI的GPT-2模型究竟有多强大？有人用它生成了一部《哈利・波特》剧本](https://zhuanlan.zhihu.com/p/57336226)
* [逆天语言模型GPT-2最新开源：345M预训练模型和1.5B参数都来了](https://zhuanlan.zhihu.com/p/64610551)
* [OpenAI的逆天语言模型，编故事以假乱真！也会问答翻译写摘要，横扫各大语言建模任务](https://zhuanlan.zhihu.com/p/56783766)



### GPT3

* [1750亿参数，GPT-3却并不「智能」](https://zhuanlan.zhihu.com/p/189715027)
* [GPT-3成精了，万物皆文本时代来临！10年内通过图灵测试？](https://zhuanlan.zhihu.com/p/165272251)
* [GPT-3王者来袭！1750亿参数少样本无需微调，网友：「调参侠」都没的当了](https://zhuanlan.zhihu.com/p/145278334)



### Big Bird

* [谷歌NLP新模型「大鸟」突破BERT限制，稀疏注意力机制更省内存](https://zhuanlan.zhihu.com/p/176658146)



### SegaBert

* [薄言AI再升级，全面改进Transformer类预训练模型，自然语言任务超越BERT](https://zhuanlan.zhihu.com/p/146952322)



### MegatronLM

* [NLP界“威震天”袭来！英伟达成功训练83亿参数史上最大语言模型](https://zhuanlan.zhihu.com/p/78102955)



### Roberta

* [BERT 王者归来！Facebook 推出 RoBERTa，碾压 XLNet 制霸三大排行榜](https://zhuanlan.zhihu.com/p/75855973)
* [BERT重夺多项测试第一名，改进之后性能追上XLNet，现已开源预训练模型](https://zhuanlan.zhihu.com/p/75856238)