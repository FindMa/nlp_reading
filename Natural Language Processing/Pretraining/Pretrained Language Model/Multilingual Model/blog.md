### M2M-100

* [github](https://github.com/pytorch/fairseq/tree/master/examples/m2m_100)

* [150亿参数大杀器！Facebook开源机器翻译新模型，同传人员或失业](https://zhuanlan.zhihu.com/p/267022759)



### mT5

* [github](https://github.com/google-research/multilingual-t5)
* [SOTA又换庄家！谷歌130亿参数多语言模型mT5重磅来袭，101种语言轻松迁移](https://zhuanlan.zhihu.com/p/269110982)



### LaBSE

* [谷歌提出多语言BERT模型：可为109种语言生成与语言无关的跨语言句子嵌入](https://zhuanlan.zhihu.com/p/191261392)



### XLM-R

* [github](https://github.com/facebookresearch/XLM)

* [Facebook最新语言模型XLM-R：多项任务刷新SOTA，超越单语BERT](https://zhuanlan.zhihu.com/p/91782784)



### M4

* [一个模型解决 103 种语言！500亿参数训练，谷歌新模型突破多语言神经翻译极限](https://zhuanlan.zhihu.com/p/86649250)



### opus-100-corpus

* [github](https://github.com/EdinburghNLP/opus-100-corpus)



### XLM

* [github](https://github.com/facebookresearch/XLM)
* [跨语言模型预训练，三大任务刷新最高性能 | Facebook](https://zhuanlan.zhihu.com/p/56152762)